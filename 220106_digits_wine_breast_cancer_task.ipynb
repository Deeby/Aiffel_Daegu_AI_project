{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "220106_digits_wine_breast_cancer_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxJka7tWUo5nZx8nn7hfiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yeonsu-Hong/Aiffel_Daegu_AI_project/blob/master/220106_digits_wine_breast_cancer_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YsARVUxjQ_0X"
      },
      "outputs": [],
      "source": [
        "# 2022년 1월 12일 제출\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2022년 1월 12일 수요일 제출\n",
        "\n",
        " Exploration 2 - 손글씨 분류, 와인 분류, 유방암 양성음성 판정\n",
        "\n",
        "\n",
        " **1. 손글씨 분류**"
      ],
      "metadata": {
        "id": "SM9mqaFemIF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. load_digits : 손글씨를 분류"
      ],
      "metadata": {
        "id": "gAz4BwccRPmO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import 하기\n",
        "\n",
        "from sklearn.datasets import load_digits  # 사이킷런에서 load_digits 모듈 불러오기\n",
        "from sklearn.model_selection import train_test_split # train_test_split 함수로 훈련 데이터를 훈련 세트와 테스트 세트로 나누는 함수. 테스트 세트로 나눌 비율은 test_size 매개변수에서 지정할수 있으며 기본값은 0.25다.\n",
        "from sklearn.metrics import classification_report # sklearn.metrics는 평가하는 모듈로 분류, 회귀, 클러스터링 알고리즘의 성능을 측정 하는 함수를 제공, classification_report 평가지표해석 (Precision, Recall, F1 score, Accuracy 등이 있다.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_WUejqDRTl4",
        "outputId": "2e9b50b5-9dcf-4887-fc9e-f2b73473fa00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 데이터 준비 \n",
        "\n",
        "digits = load_digits()\n",
        "# 싸이킷런의 digits 데이터 불러오기 (변수로 digits 지정)\n",
        "print(dir(digits))\n",
        "# dir()는 개체가 어떤 변수와 메서드를 가지고 있는지 나열함.\n",
        "digits.keys()\n",
        "# digits에는 어떤 정보가 담겨 있는지, keys()라는 메서드로 확인!\n",
        "digits_label = digits.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq2DFwTlTBmR",
        "outputId": "91584988-9f79-4237-df75-90e5ea1c1489"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "\n",
        "digits_data = digits.data\n",
        "# Feature data 지정하기\n",
        "print(digits_data.shape)\n",
        "# shape는 배열의 형상 정보를 출력! "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sofJBLYGTF4g",
        "outputId": "237b6242-99db-4270-f2d3-bf76a3c7bc44"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Label data 지정하기\n",
        "digits_data[0] # 샘플로 하나의 데이터 확인\n",
        "\n",
        "digits_label = digits.target\n",
        "print(digits_label.shape)\n",
        "digits_label\n",
        "\n",
        "# 총 1797개의 데이터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjraLwqrVfP4",
        "outputId": "8fa928e0-efdd-4952-d911-7eaf0486dea0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1797,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Target Names 출력하기!\n",
        "\n",
        "digits.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pizp_RAVtnJ",
        "outputId": "e6ca647b-ffb4-4ca9-c0aa-996a5431d0ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** 데이터 Describe 해보기!\n",
        "\n",
        "print(digits.DESCR) # DESCR은 desciption이다. 데이터 셋에 대한 설명이 나온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWW8RMQIWEjh",
        "outputId": "6b8eea9f-27c0-4f7c-edf4-3e5af539a318"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _digits_dataset:\n",
            "\n",
            "Optical recognition of handwritten digits dataset\n",
            "--------------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 1797\n",
            "    :Number of Attributes: 64\n",
            "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
            "    :Missing Attribute Values: None\n",
            "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
            "    :Date: July; 1998\n",
            "\n",
            "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
            "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
            "\n",
            "The data set contains images of hand-written digits: 10 classes where\n",
            "each class refers to a digit.\n",
            "\n",
            "Preprocessing programs made available by NIST were used to extract\n",
            "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
            "total of 43 people, 30 contributed to the training set and different 13\n",
            "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
            "4x4 and the number of on pixels are counted in each block. This generates\n",
            "an input matrix of 8x8 where each element is an integer in the range\n",
            "0..16. This reduces dimensionality and gives invariance to small\n",
            "distortions.\n",
            "\n",
            "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
            "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
            "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
            "1994.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
            "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
            "    Graduate Studies in Science and Engineering, Bogazici University.\n",
            "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
            "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
            "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
            "    Electrical and Electronic Engineering Nanyang Technological University.\n",
            "    2005.\n",
            "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
            "    Algorithm. NIPS. 2000.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state= 7)\n",
        "# test_size는 양이 몇만단위가 아니라서 줄이지 않고 기존 템플릿으로 20%로 지정하였다.\n",
        "\n"
      ],
      "metadata": {
        "id": "zDNP0Q6LWHdg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) 다양한 모델로 학습시켜보기\n",
        "\n",
        "# 1. Decision Tree 사용\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# import 하기!\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rc5GvEOWlA4",
        "outputId": "00793657-28a5-4cc5-ab9e-557bf1278645"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.81      0.81      0.81        42\n",
            "           2       0.79      0.82      0.80        40\n",
            "           3       0.79      0.91      0.85        34\n",
            "           4       0.83      0.95      0.89        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       0.84      0.93      0.88        28\n",
            "           7       0.96      0.82      0.89        33\n",
            "           8       0.88      0.65      0.75        43\n",
            "           9       0.78      0.78      0.78        32\n",
            "\n",
            "    accuracy                           0.86       360\n",
            "   macro avg       0.86      0.86      0.86       360\n",
            "weighted avg       0.86      0.86      0.85       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# precision(정확도) : 숫자 0이라고 예측한 데이터의 100%가 정확하였고 1은 81%.... 밑에 9는 78%의 정확도를 나타내었다.\n",
        "# 정확도 = TP + TN / TP + FP + TN + FN (실제 데이터와 예측 데이터를 비교하여 같은 지 판단한다. )\n",
        "\n",
        "# recall (재현율) : 숫자 8에서 65%로 낮은 값이 나왔다.\n",
        "# 재현율 = TP / TP + FN (실제 맞춘 대상중에서 예측값이 일치하는 비율)\n",
        "\n",
        "# f1 score : 정밀도와 재현율을 결합한 조화평균 지표로 값이 클수록 모형이 정확하다. \n",
        "# f1 = 2 / (1/recall) + (1/precision) = 2 * (precision*recall)/(precision+recall)\n",
        "\n",
        "# support는 각 클래스 별 데이터 개수를 의미!\n",
        "# macro avg : 단순 평균\n",
        "# weighted avg : 각 클래스에 속하는 표본의 개수로 가중 평균 \n",
        "\n",
        "# -> 가중 산술 평균은 자료의 평균을 구할 때 자료 값의 중요도나 영향 정도에 해당하는 가중치를 반영하여 구한 평균값이다.\n",
        "\n",
        "\n",
        "# Decision Tree모델에서 sklearn.metrics를 통해 분석해보니 데이터 특성상 실제 True인 답을 False라고 예측하는 False Negarive(FN)의 비중을 줄여야 한다고 생각한다. \n",
        "# 그래서 recall (재현율)을 고려하여야 하고, F! score도 정밀도와 재현율을 결합한 지표이니 같이 분석하면 될것 같다.\n",
        "# 사실 모든 모델들이 0.86, 0.85 왔다갔다해서 정확도 차이는 없다고 생각한다.\n",
        "\n",
        "\n",
        "# 뒤쪽에 다른 모델들 성능을 비교 분석한다.\n"
      ],
      "metadata": {
        "id": "0fS6xHLEW58q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Random Forest 사용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# import 하기!\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state= 7)\n",
        "# 모델 비교를 위해서 Decision Tree 동일한 split 조건!\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7MszyRHeLxe",
        "outputId": "b5b3f152-69e5-4351-9db7-118e55b2bea8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.93      1.00      0.97        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       0.93      1.00      0.96        37\n",
            "           5       0.90      0.96      0.93        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.94      0.97      0.96        33\n",
            "           8       1.00      0.84      0.91        43\n",
            "           9       0.94      0.94      0.94        32\n",
            "\n",
            "    accuracy                           0.96       360\n",
            "   macro avg       0.96      0.96      0.96       360\n",
            "weighted avg       0.97      0.96      0.96       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# precision(정확도) : 위에 보다도 정확성이 높다.\n",
        "# 정확도 = TP + TN / TP + FP + TN + FN (실제 데이터와 예측 데이터를 비교하여 같은 지 판단한다. )\n",
        "\n",
        "# recall (재현율) : 마찬가지!\n",
        "# 재현율 = TP / TP + FN (실제 맞춘 대상중에서 예측값이 일치하는 비율)\n",
        "\n",
        "# f1 score : 정밀도와 재현율을 결합한 조화평균 지표로 값이 클수록 모형이 정확하다. \n",
        "# f1 = 2 / (1/recall) + (1/precision) = 2 * (precision*recall)/(precision+recall)\n",
        "\n",
        "# support는 각 클래스 별 데이터 개수를 의미!\n",
        "# macro avg : 단순 평균\n",
        "# weighted avg : 각 클래스에 속하는 표본의 개수로 가중 평균 \n",
        "\n",
        "# -> 가중 산술 평균은 자료의 평균을 구할 때 자료 값의 중요도나 영향 정도에 해당하는 가중치를 반영하여 구한 평균값이다.\n",
        "\n",
        "\n",
        "# Random Forest모델에서 sklearn.metrics를 통해 분석해보니 데이터 특성상 실제 True인 답을 False라고 예측하는 False Negarive(FN)의 비중을 줄여야 한다고 생각한다. \n",
        "# 그래서 recall (재현율)을 고려하여야 하고, F! score도 정밀도와 재현율을 결합한 지표이니 같이 분석하면 될것 같다.\n",
        "# 사실 모든 모델들이 0.96, 0.97 왔다갔다해서 정확도 차이는 없다고 생각한다.\n",
        "\n",
        "# Decision Tree 보다는 정확성이 현저하게 높아졌다.\n",
        "# 이유는 Decision Tree를 여러개 모아놓은 Random Forest 특성상 여러개 tree 모델을 합쳐놓음으로써 decision tree의 단점을 극복한 모델이여서 그런것이라 판단된다.\n",
        "# 앙상블(Ensemble) 기법이라고도 한다.\n",
        "\n",
        "# 추가적인 Random Forest는 상위 모델들이 예측하는 편향된 결과보다, 다양한 모델들의 결과를 반영함으로써 더 다양한 데이터에 대한 의사결정을 내릴 수 있게 한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "zcgPHG_-e-Ne"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. SVM 사용\n",
        "from sklearn import svm\n",
        "# import 하기!\n",
        "svm_model = svm.SVC()\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state= 7)\n",
        "# 모델 비교를 위해서 동일한 split 조건!\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-Qzdti5gpPW",
        "outputId": "4f5823f8-1343-41d0-ddaa-8073eb40cc9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      1.00      0.98        42\n",
            "           2       1.00      1.00      1.00        40\n",
            "           3       1.00      1.00      1.00        34\n",
            "           4       1.00      1.00      1.00        37\n",
            "           5       0.93      1.00      0.97        28\n",
            "           6       1.00      1.00      1.00        28\n",
            "           7       1.00      1.00      1.00        33\n",
            "           8       1.00      0.93      0.96        43\n",
            "           9       1.00      0.97      0.98        32\n",
            "\n",
            "    accuracy                           0.99       360\n",
            "   macro avg       0.99      0.99      0.99       360\n",
            "weighted avg       0.99      0.99      0.99       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# SVM 같은 경우 위의 tree 계열 두 모델들 보다 정확성이 월등히 높아졌다. (99%)\n",
        "# 글씨 분석에서는 SVM model이 좋은 것 같다.\n",
        "\n",
        "# SVM 장단점\n",
        "# 장점 :\n",
        "# - 다양한 하이브러리로 사용하기 쉬우며 분류, 회귀 예측 문제에 동시에 활용할 수 있다.\n",
        "# - 신경망 기법에 비해 적은 데이터로 학습이 가능하며 과대적합, 과소적합 정도가 덜하다\n",
        "\n",
        "# 단점 :\n",
        "# - 이진 분류만 가능하며 데이터가 많을 시 모델 학습 시간이 오래 소요된다.\n",
        "# - 각각 분류에 대한 SVM 모델 구축이 필요하다."
      ],
      "metadata": {
        "id": "2FxTgDpvhJ09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. SGD Classifier 모델 사용\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "# import 하기!\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state= 7)\n",
        "# 모델 비교를 위해서 동일한 split 조건!\n",
        "\n",
        "# sgd model 학습\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sADU41FiqmN",
        "outputId": "2a3951b7-58c0-4272-d8f6-174b4a934cd8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      0.88      0.91        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.91      0.88      0.90        34\n",
            "           4       1.00      0.95      0.97        37\n",
            "           5       0.90      1.00      0.95        28\n",
            "           6       0.96      0.93      0.95        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.87      0.93      0.90        43\n",
            "           9       0.94      0.94      0.94        32\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# SGD Classifier 같은 경우 준수한 결과가 나왔다. (95%)\n",
        "\n"
      ],
      "metadata": {
        "id": "gvBVavaRi44L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. # Logistic Regression 모델 사용\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "# import 하기!\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state= 7)\n",
        "# 모델 비교를 위해서 동일한 split 조건!\n",
        "\n",
        "# Logistic Regression 학습\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSa8gRtGkfGf",
        "outputId": "2942aa73-eb4c-472e-faf8-df303b0a9e6c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        43\n",
            "           1       0.95      0.95      0.95        42\n",
            "           2       0.98      1.00      0.99        40\n",
            "           3       0.94      0.97      0.96        34\n",
            "           4       0.97      1.00      0.99        37\n",
            "           5       0.82      0.96      0.89        28\n",
            "           6       1.00      0.96      0.98        28\n",
            "           7       0.97      0.97      0.97        33\n",
            "           8       0.92      0.81      0.86        43\n",
            "           9       0.97      0.91      0.94        32\n",
            "\n",
            "    accuracy                           0.95       360\n",
            "   macro avg       0.95      0.95      0.95       360\n",
            "weighted avg       0.95      0.95      0.95       360\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# Logistic Regression 같은 경우도 준수한 결과가 나왔다. (95%)\n",
        "\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "\n",
        "# 가장 널리 알려진 선형 분류 알고리즘.\n",
        "# 소프트맥스 함수를 사용한 다중 클래스 분류 알고리즘이며, 다중 클래스 분류를 위한 로지스틱 회귀를 소프트맥스 회귀(Softmax regression)라고도 한다.\n",
        "# 이름은 회귀지만, 실제로는 분류를 수행한다.\n",
        "\n",
        "\n",
        "# 소프트맥스 함수 : 클래스가 N개일 때, N차원의 벡터가 각 클래스가 정답일 확률을 표현하도록 정규화를 해주는 함수. 위의 그림은 4차원의 벡터를 입력으로 받아 3개의 클래스를 예측하는 경우의 소프트맥스 회귀의 동작 과정을 보여준다.\n",
        "# 3개의 클래스 중 1개의 클래스를 예측해야 하므로 소프트맥스 회귀의 출력은 3차원의 벡터고, 각 벡터의 차원은 특정 클래스일 확률이다.\n",
        "# 오차와 실제값의 차이를 줄이는 과정에서 가중치와 편향이 학습된다.\n",
        "# ----> 더 간단하게 쉽게 얘기를 하자면 다중 분류에서 여러 선형 방정식의 출력 결과를 정규화하여 합이 1이 되도록 만든다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8_T1sf1ckrxX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 평가 : 손글씨에서는 SVM 모델이 가장 좋다"
      ],
      "metadata": {
        "id": "30uLs612lgpv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        " **2. 와인 분류**"
      ],
      "metadata": {
        "id": "uVtDj2qumo39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import 하기\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "VF6znSTOmsB1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 데이터 준비 \n",
        "\n",
        "wine = load_wine()\n",
        "# 싸이킷런의 digits 데이터 불러오기 (변수로 digits 지정)\n",
        "print(dir(wine))\n",
        "# dir()는 개체가 어떤 변수와 메서드를 가지고 있는지 나열함.\n",
        "wine.keys()\n",
        "# digits에는 어떤 정보가 담겨 있는지, keys()라는 메서드로 확인!\n",
        "wine_label = wine.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np7f1ITWnWf4",
        "outputId": "e35e55b8-f903-4231-b90b-dac26b625797"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "\n",
        "wine_data = wine.data\n",
        "# Feature data 지정하기\n",
        "print(wine_data.shape)\n",
        "# shape는 배열의 형상 정보를 출력! "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufqf_gNunrUB",
        "outputId": "3d9d15c8-4667-4498-b5d4-3ad7e53cfd01"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Label data 지정하기\n",
        "wine_data[0] # 샘플로 하나의 데이터 확인\n",
        "\n",
        "wine_label = wine.target\n",
        "print(wine_label.shape)\n",
        "wine_label\n",
        "\n",
        "# 총 178개의 데이터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUyoML4XnwSv",
        "outputId": "652d7afa-ade4-4a18-9edc-d85d22b23d24"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Target Names 출력하기!\n",
        "\n",
        "wine.target_names\n",
        "\n",
        "# 와인을 class 0, 1, 2로 구별한다 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMYUbWncoL7Y",
        "outputId": "ec87faaa-b33e-46e5-dec8-d181bba3ef32"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** 데이터 Describe 해보기!\n",
        "\n",
        "print(wine.DESCR) # DESCR은 desciption이다. 데이터 셋에 대한 설명이 나온다.\n",
        "# 주석산 농도, 알콜 등 13가지의 기준으로 3개의 클래스를 나눈다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzGr3rHQoPKo",
        "outputId": "2bbe783a-a331-4e4a-93f5-be18147ff3d4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
            "    Ash:                          1.36  3.23    2.36  0.27\n",
            "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
            "    Magnesium:                    70.0 162.0    99.7  14.3\n",
            "    Total Phenols:                0.98  3.88    2.29  0.63\n",
            "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
            "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
            "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
            "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
            "    Hue:                          0.48  1.71    0.96  0.23\n",
            "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
            "    Proline:                       278  1680     746   315\n",
            "    ============================= ==== ===== ======= =====\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "This is a copy of UCI ML Wine recognition datasets.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
            "\n",
            "The data is the results of a chemical analysis of wines grown in the same\n",
            "region in Italy by three different cultivators. There are thirteen different\n",
            "measurements taken for different constituents found in the three types of\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.3, random_state= 7)\n",
        "# test_size는 데이터 수가 적어서 30%로 지정하였다. (손글씨는 20%)\n",
        "\n"
      ],
      "metadata": {
        "id": "zIcjOTSRoSHQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) 다양한 모델로 학습시켜보기\n",
        "\n",
        "# 1. Decision Tree 사용\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# import 하기!\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEr1AYg5oo0A",
        "outputId": "c41ae38c-c694-4d4c-b1e6-d253d3e6f90c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.92      0.86        13\n",
            "           1       0.91      0.88      0.89        24\n",
            "           2       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.91        54\n",
            "   macro avg       0.90      0.91      0.91        54\n",
            "weighted avg       0.91      0.91      0.91        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# accuracy는 91% 준수하게 나온거 같다."
      ],
      "metadata": {
        "id": "eQvaXdNooqIw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Random Forest 사용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# import 하기!\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmbXqSLBo-oI",
        "outputId": "e369545e-50ab-4372-bbd5-6f3cda4e0e84"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00        24\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           1.00        54\n",
            "   macro avg       1.00      1.00      1.00        54\n",
            "weighted avg       1.00      1.00      1.00        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# accuracy는 100%가 나왔다. digits에서는 96 ~ 97%가 나왔는데, 여기서는 100프로 달성"
      ],
      "metadata": {
        "id": "pOJ5qSHHpJ7Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. SVM 사용\n",
        "from sklearn import svm\n",
        "# import 하기!\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "# 모델 비교를 위해서 동일한 split 조건!\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtRXnuoWpRxj",
        "outputId": "8540e06e-48c6-46d8-ba55-987ec08161d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.90        13\n",
            "           1       0.58      0.92      0.71        24\n",
            "           2       0.00      0.00      0.00        17\n",
            "\n",
            "    accuracy                           0.65        54\n",
            "   macro avg       0.46      0.64      0.54        54\n",
            "weighted avg       0.45      0.65      0.53        54\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# SVM 같은 경우 위의 정확도가 처참하다. (digits에서는 99% 정확도가 나왔었음.)\n",
        "# 기준이 많아서 그런지는 몰라도 좋지 않은 모델인거 같다."
      ],
      "metadata": {
        "id": "83QageqJpdjR"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. SGD Classifier 모델 사용\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "# import 하기!\n",
        "\n",
        "# sgd model 학습\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcB29_4LrtII",
        "outputId": "e4211170-4471-4f1c-b531-31f4dd0d4fe2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.77      0.87        13\n",
            "           1       0.93      0.54      0.68        24\n",
            "           2       0.53      0.94      0.68        17\n",
            "\n",
            "    accuracy                           0.72        54\n",
            "   macro avg       0.82      0.75      0.74        54\n",
            "weighted avg       0.82      0.72      0.73        54\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# 역시 정확도가 좋지 못하다. 부적합한 모델!"
      ],
      "metadata": {
        "id": "7uSyQ9-UrvdB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. # Logistic Regression 모델 사용\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "# import 하기!\n",
        "\n",
        "# Logistic Regression 학습\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh5GaZnQr3qh",
        "outputId": "d95d354d-947b-44a0-ad53-4ef29ebe2da4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.92      0.86        13\n",
            "           1       0.95      0.88      0.91        24\n",
            "           2       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           0.93        54\n",
            "   macro avg       0.92      0.93      0.92        54\n",
            "weighted avg       0.93      0.93      0.93        54\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# 정확도가 높은편이다. 93% \n",
        "# Random Forest 다음으로 고려해 볼만한 모델 (와인 분류에서)"
      ],
      "metadata": {
        "id": "XQzY7WzMr5NK"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3. 유방암 양성음성 판별**"
      ],
      "metadata": {
        "id": "hYnD7Ljcsoti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. load_breast_cancer : 유방암"
      ],
      "metadata": {
        "id": "VPSngpf0sv38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 필요한 모듈 import 하기\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "IBHVxE90sUEA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 데이터 준비 \n",
        "\n",
        "breast_cancer = load_breast_cancer()\n",
        "# 싸이킷런의 digits 데이터 불러오기 (변수로 digits 지정)\n",
        "print(dir(breast_cancer))\n",
        "# dir()는 개체가 어떤 변수와 메서드를 가지고 있는지 나열함.\n",
        "breast_cancer.keys()\n",
        "# digits에는 어떤 정보가 담겨 있는지, keys()라는 메서드로 확인!\n",
        "breast_cancer_label = breast_cancer.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f15NtpNs1fH",
        "outputId": "3a7032c3-b21c-4cb2-ba3a-e0542ff73a7a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DESCR', 'data', 'data_module', 'feature_names', 'filename', 'frame', 'target', 'target_names']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) 데이터 이해하기\n",
        "\n",
        "breast_cancer_data = breast_cancer.data\n",
        "# Feature data 지정하기\n",
        "print(breast_cancer_data.shape)\n",
        "# shape는 배열의 형상 정보를 출력! "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkNVcGeitJV5",
        "outputId": "dc24e1ae-a06f-4a38-da99-4ab4b33e7113"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Label data 지정하기\n",
        "breast_cancer_data[0] # 샘플로 하나의 데이터 확인\n",
        "\n",
        "breast_cancer_label = breast_cancer.target\n",
        "print(breast_cancer_label.shape)\n",
        "breast_cancer_label\n",
        "\n",
        "# 총 569개의 데이터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T90o3U4xtRbC",
        "outputId": "42bef0db-604d-418e-dbb8-511ca0eba780"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** Target Names 출력하기!\n",
        "\n",
        "breast_cancer.target_names\n",
        "\n",
        "# marlignant 양성, benign 음성 \n",
        "# 이진분류의 일종으로 판단됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tdep7QCtbf5",
        "outputId": "e8311ddb-ab70-485d-8c63-91110ae8ccf4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ****** 데이터 Describe 해보기!\n",
        "\n",
        "print(breast_cancer.DESCR) # DESCR은 desciption이다. 데이터 셋에 대한 설명이 나온다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBaMfTEOtiYi",
        "outputId": "d47c1b0d-90a3-40fc-bd8b-c0a4cd5ef61b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry\n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        worst/largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
            "        10 is Radius SE, field 20 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 굉장히 복잡한 엄밀하고 복잡한 기준을 가지고 있다.\n",
        "\n",
        "# 직경, 직감, 부위, 대칭성, 악성 종양에서의 분류성질도 나타내고 있다. 의학정보 데이터에서는 배경 지식도 중요한듯 보인다.\n",
        "# 다행히 생명공학을 전공하여서 대충은 보인다. (암연구소 연구직 인턴 출신이라서 대충은 보인다.)\n",
        "\n",
        "# Refrence에 들어가서 논문을 보고 싶으나, 시간이 많이 걸리는 관계로 pass"
      ],
      "metadata": {
        "id": "BBtobOOAtuFK"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Train, test 데이터 분리\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label, test_size=0.2, random_state= 7)\n",
        "# test_size는 20%로 지정하였다.\n",
        "\n"
      ],
      "metadata": {
        "id": "s2RP2AQquHwC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) 다양한 모델로 학습시켜보기\n",
        "\n",
        "# 1. Decision Tree 사용\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# import 하기!\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(random_state=32)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred = decision_tree.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OkUpG3quh1h",
        "outputId": "85f0cffe-0f88-4d8c-e2cd-2e94ca030a8d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87        40\n",
            "           1       0.91      0.96      0.93        74\n",
            "\n",
            "    accuracy                           0.91       114\n",
            "   macro avg       0.91      0.89      0.90       114\n",
            "weighted avg       0.91      0.91      0.91       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# 91%의 accuracy를 보인다. \n",
        "# 암을 진단하는 경우 실제 환자를 한명이라도 놓치면 안된다.\n",
        "# 양성(환자)를 음성(정상)으로 판단 (FN)하면 안되기 때문에 recall이 중요하다.\n",
        "# precision보다 recall을 눈여겨 봐야 한다.\n",
        "\n",
        "# 그리고 100%의 모델을 써야 한다. 의료 정보 데이터라서 100%의 accuracy가 중요할 것이다."
      ],
      "metadata": {
        "id": "PB9fBZpnuv4y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Random Forest 사용\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# import 하기!\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=32)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1tn9BwwvLKD",
        "outputId": "14fd9983-58cd-47ac-c467-05500912284d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        74\n",
            "\n",
            "    accuracy                           1.00       114\n",
            "   macro avg       1.00      1.00      1.00       114\n",
            "weighted avg       1.00      1.00      1.00       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# 100%의 accuracy"
      ],
      "metadata": {
        "id": "22lY0pZsvOfD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. SVM 사용\n",
        "from sklearn import svm\n",
        "# import 하기!\n",
        "svm_model = svm.SVC()\n",
        "\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmXihOjBvS-z",
        "outputId": "9b0e4345-bf4c-48d0-8ec3-224215b04348"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.72      0.84        40\n",
            "           1       0.87      1.00      0.93        74\n",
            "\n",
            "    accuracy                           0.90       114\n",
            "   macro avg       0.94      0.86      0.89       114\n",
            "weighted avg       0.92      0.90      0.90       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# recall의 90%의 accuracy "
      ],
      "metadata": {
        "id": "5miTJ0rDvX3a"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. SGD Classifier 모델 사용\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd_model = SGDClassifier()\n",
        "# import 하기!\n",
        "\n",
        "# sgd model 학습\n",
        "sgd_model.fit(X_train, y_train)\n",
        "y_pred = sgd_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9nKBmlkvl9b",
        "outputId": "eae9c52c-6e09-40da-e85b-45f51a079983"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.70      0.82        40\n",
            "           1       0.86      1.00      0.92        74\n",
            "\n",
            "    accuracy                           0.89       114\n",
            "   macro avg       0.93      0.85      0.87       114\n",
            "weighted avg       0.91      0.89      0.89       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# recall의 89%의 accuracy "
      ],
      "metadata": {
        "id": "z22ZXHOnvn4r"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. # Logistic Regression 모델 사용\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_model = LogisticRegression()\n",
        "# import 하기!\n",
        "\n",
        "# Logistic Regression 학습\n",
        "logistic_model.fit(X_train, y_train)\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV0wYhssvqUr",
        "outputId": "3ebb8a04-6eb2-4fdc-ea09-5643b353e5bc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        40\n",
            "           1       0.91      1.00      0.95        74\n",
            "\n",
            "    accuracy                           0.94       114\n",
            "   macro avg       0.96      0.91      0.93       114\n",
            "weighted avg       0.94      0.94      0.94       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (6) 모델을 평가해보기\n",
        "# 출력된 값의 해석\n",
        "\n",
        "# recall의 94%의 accuracy "
      ],
      "metadata": {
        "id": "fRRmSZoovtg7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "\n",
        "# 의료 정보 데이터 같은 경우에는 100% 정확성이 중요하므로 Random forest 모델을 사용한다."
      ],
      "metadata": {
        "id": "J9AcZbdovv3r"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 총평\n",
        "\n",
        "# 머신러닝의 예측 성공률은 결국 얼마나 정확한 경계선을 그어서 판별하느냐에 따라 달렸다.\n",
        "# 여러 모델들을 위에서 썼지만, 딥러닝으로 넘어가서의 실습도 중요할 것 같다. \n",
        "# 위의 똑같은 데이터들을 딥러닝으로 학습시키는 방법은 좀더 학습이 진행 된 후에 그대로 구현을 할 예정"
      ],
      "metadata": {
        "id": "eBJtXHMov5ZL"
      },
      "execution_count": 73,
      "outputs": []
    }
  ]
}